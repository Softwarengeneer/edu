# [#1. Жизненный цикл ПО.](https://www.youtube.com/watch?v=wWea876rbBs&list=PLBWafxh1dFuykoWaAt7HiMOGgWXRvAN5V&index=1)

# [#2. RUP, UML и гибкие методологии разработки](https://www.youtube.com/watch?v=WQjJZyV4eNw&list=PLBWafxh1dFuykoWaAt7HiMOGgWXRvAN5V&index=2)

# [#3. Требования и риски](https://www.youtube.com/watch?v=CFMzn5dh1aE&list=PLBWafxh1dFuykoWaAt7HiMOGgWXRvAN5V&index=3)

# [#4. Управление изменениям, системы контроля версий](https://www.youtube.com/watch?v=-i5zCy0_EnA&list=PLBWafxh1dFuykoWaAt7HiMOGgWXRvAN5V&index=4)

стр. 66 Конспект

`00:47` : Что такое изменение. Атрибуты изменений

Общая модель:
- Запрос и анализ
    - `Require new functionality [Customer]` / Encounter problem
    - `Technical feasibility[Project Manager]`: Необходимость и осуществимость изменений
        - Формирует документ / артефакт 
    - `Costs & benefits[Project Manager]`: Анализирует риски и выгоду для пользователя
        - Отражается в журнале изменения
- Подтверждение и реализация
    - `Analyze change impact`: Анализируется влияние на другие части системы и возможные последствия для пользователя
        - Появление артефакта
        - _Регрессионное тестирование_ - тестирование по максимально известным тестам, чтобы удостовериться, что новые фичи не мешают старым работать и не вносят новые баги в старый код или в новый код.
    - `Create planning`: Определение необходимых ресурсов, времени, графика осуществления действий.
        - Появление артефакта
    - `Realisation[Change builder]`: Непосредственно реализация изменения.
        - Создаются изменения `Items`
        - Внесение изменений в связанную документацию
        - Выпуск новой версии продукта
        - Артфакты: `Test report`, `Documentation`, `System Release`
  - Проверка и закрытие реализации
    - `Change verification[Project Manager]`: Утверждение изменений (иногда у заказчика) и формальное закрепление.
    

`10:20` : Системы контроля версий

Основные типы VCS:
- На основе файловой системы
    - С экспортом клиентам
- Централизованные
    - Репозиторий на сервере
    - Самые распространенные
    - Пример: SVN
- Распределенные 
    - Репозиторий на каждом клиенте с центральным хранилищем на сервере
    - Пример: Git

`15:25` : Почему появились VSC? Проблема одновременной модификации файлов

Причины:
- Необходимость журналирования изменений
- Командная работа

Одновременная модификация файлов:
- Lock-modify-unlock
    - В основном в VCS на файловой системе
    - Минус: Пока один человек меняет, все ждут
- Copy-modify-merge
    - Своя рабочая копия у каждого разработчика 
    - Минус: Трудности слияния рабочих копий
- Мгновенное отображение изменений невозможно (как Google Docs)
    - Срез проекта должен быть уникальным
    - Есть промежуточные стадии типа компилирования


`19:25` : Subversion

стр. 73

Репозиторий (по SVN) - зафиксированная версия файлов на определенный момент времени (релиз/ревизия `r2342`)

`trunk` - основная ветвь разработки 

`branches` - хранение модификаций продукта
- Можно хранить отдельно релизы (значимые изменения), ветки для фичей, вендорные штуки

`tags` - функционально целостные изменения
- Минорные версии
- Исправление дефектов

Алгоритм работы с SVN:

Утро:
- `svn update` - обновление рабочей копии

Работа:
- `svn add/delete/copy/move/mkdir` - Изменения файлов
- `svn status` - Просмотр изменений
- `svn revert` - Откат изменений
  
Фиксация изменений:
- `svn update` - Загрузка изменений других разработчиков
  
Разрешение конфликтов
- `svn commit` - тут понятно


`29:48` : Конфликты и слияния

стр. 77

Конфликты:
- Содержимого файлов
    - Изменения внутри файлов
- Структуры файлов
    - Перемешение, переименовани файлов
    

`37:50` : Git

стр. 81

Главная идея Git - шарить коммиты. Распределенная VCS развивалась как VCS для разработки ядра Linux.
Разработчикам было удобно писать отдельные модули.
Но Git используется обычно по сценарию централизованной VCS.

`47:55` : Ветвления в Git


`56:00` : Удобная надстройка над Git - Git flow
- Идея: версионирование в терминах версий, а не операций

| |  Тип операции  | Команда | |
| :--- | :--- | :--- | :--- |
| |  `init`  | `start` | |
| | `feature` | `finish` | |
| `git flow` | `release` | `publish` | NAME |
| | `hotfix` | `pull` | |

`58:44` : SVN vs Git

[Статья "10 things I have about git"](https://stevebennett.me/2012/02/24/10-things-i-hate-about-git/)

# [#5 Системы автоматической сборки](https://www.youtube.com/watch?v=RFgqHUx7cgs&list=PLBWafxh1dFuykoWaAt7HiMOGgWXRvAN5V&index=5) 

`00:00` : Мотивация. Предпосылки возникновения систем автоматической сборки

стр. 88

Причины появления:
- Скрипт сборки сложно поддерживать в актуальном состоянии с развитием проекта
- Сборка с учетом платформно-зависимых особенностей:
    - Разрядность 32/64:
        - Математические операции, определяющие разрядность
        - Слово памяти, определенное для передачи
        - Разрядность адреса на шине процессора
    - Размеры и организация кэшей
    - Разное размещение конфигурации:
        - Linux: обычно в `~/etc/`
        - Windows: в реестре `C:\Windows\System32\config\` (файлы `DEFAULT`, `SAM`, `SOFTWARE`, `SECURITY` и `SYSTEM`)
    - Стандарты POSIX
    - Необходимость создания для программ единого библиотечного окружения
- Медленная сборка 
    - Большое количество файлов для компиляции
        - Компиляция C++ кода с максимальной оптимизацией занимает много времени > ночные сборки
        - Было бы неплохо компилировать отдельные части проекта, а не каждый раз целиком
    - Не было параллелизма 

`11:34` : Классические средства сборки Make (C) и Ant (java)

стр. 92

Средства автоматической сборки:
- Императивные
    - Задаем последовательность сборки файлов

Идея: вместо написания скриптов, напишем язык, который бы это дело автоматизировал

Особенности:
- Свои специальные языки
- Можно задать целевую систему для сборки
- Средства автоматического определения платформы
- _Декларативная сборка_ - не "как", а "что" вы хотите собрать
    - Более "мудрая" логика вокруг +- такого-же императивной сборки
- Интеграция с build-серверами
- Автотесты
- Распараллеливание (иногда многомашинный режим работы)

`15:25` : Make и  Makefile

стр. 93

Исходные коды `.c`, `.h` --> Объектные файлы `.o` --> Бинарные файлы

Конфигурация определяется с помощью маркеров определения. 
В них задаются флаги, которые нужно выдать линковщику, компилятору...

[Makefile для самых маленьких. Habr](https://habr.com/ru/post/155201/)

Суть:
```
цель: зависимости
[tab] команда
```

Упрощенная структура makefile:

Блок переменных
```
CC=g++
CFLAGS= -c -Wall
```
Таргет
```
all: target-name
```
Описание сборки
```
target-name: main.o file1.o 

main.o: main.cpp
    $(CC) $(CFLAGS) main.cpp 

clean:
	rm -rf *.o hello
```
Супер крутой универсальный makefile:
```
CC=g++
CFLAGS=-c -Wall
LDFLAGS=
SOURCES=main.cpp hello.cpp factorial.cpp
OBJECTS=$(SOURCES:.cpp=.o)
EXECUTABLE=hello

all: $(SOURCES) $(EXECUTABLE)
	
$(EXECUTABLE): $(OBJECTS) 
	$(CC) $(LDFLAGS) $(OBJECTS) -o $@

.cpp.o:
	$(CC) $(CFLAGS) $< -o $@
```

`19:53` : Ant - сборка java-программ

стр. 94

[Ant - быстрый старт. Habr](https://habr.com/ru/post/323204/)

[Видео автора статьи](https://www.youtube.com/watch?v=FHkzQooUw1Q)

[Хороший гайд для лабы с Ant](http://java-online.ru/blog-ant.xhtml)

- Императивная система сборки
- Управляется файлом build.xml

Пример build.xml:
```
<?xml version="1.0"?>
<project name="HelloWorld" default="run">
    <target name="compile">
        <mkdir dir="build/classes"/>
        <javac destdir="build/classes" includeantruntime="false">
            <src path="src"/>
        </javac>
    </target>
    <target name="run" depends="compile">
        <java classname="HelloWorld" classpath="build/classes"/>
    </target>
    <target name="clean">
        <delete dir="build"/>
    </target>
</project>
```
- Можно создавать переменные
```
<property name="build.dir" value="/tmp"/>
```
- Можно загружаться из файла
```
<property file="build.props" />
```
- Можно задавать переменное окружение
```
<property environment="env" />
<echo message="Shell path is ${env.PATH}" />
```

# TODO: расписать основные команды для защиты

Команды Ant делятся на:
- Для работы с файлами
- Компиляция
- Размещение на сервере
- Внешний запуск

В Ant так много команд для **кроссплатформенности**. 
В разных системах они могут иметь разную реализацию или вообще не существовать. 
Все, необходимое для сборки, уже реализовано внутри утилиты.

`24:18` : Декларативная система Java-сборки `Maven`

- Детали сборки выносятся на знание плагинов. Плагины сами решают как им собираться
- Для сборки проекта используется `POM.xml` (Project Object Model):
    - Имя, версия, тип приложения
    - Местонахождение исходных кодов
    - Зависимости
    - Плагины - средства, используемые во время сборки
    - Профили - альтернативные конфигурации проекта
        - Разные целевые машины
        - Сборка с максимальной оптимизацией и тд
    
`26:20` : Центральный репозиторий - причина популярности Maven
- `mvn install`
- Читает `pom.xml`
- Скачка/обновление плагинов в локальный репозиторий
- Зависимости передаются Maven ядл компиляции

`30:04` : Структура проекта для Maven

стр. 99

Декларативность накладывает определенные требования для структуры проекта.

`target` - рабочая и целевая директории

`src/main` - основные исходные файлы
- `src/main/java` - исходники .java
- `src/main/webapp` - исходники web-страниц, jsp, js, css
- `src/main/resources` - исходники, которые не нужно компилировать

`src/test` - исходники для тестов
- `src/test/java`
- `src/test/resources`
    
Naming-конвенция GAV - groupId:artefact:version
```=
<artifact>
  <groupId>org.example.group</groupId>
  <artifactId>example-artifact</artifactId>
  <version>1.2.0</version>
</artifact>
```

`34:05` : Зависимости внутри Maven

стр. 101

Транзитивные = вложенные:
- GAV
- Scope: `compile`, `provided` (для серверов приложений), `test`, `runtime` - место в жизненном цикле компиляции, куда будет поставлена ваша зависимость
- Type: `jar`, `pom`, `war`, `ear`, `zip`...

`34:08` : Жизненный цикл Maven

стр. 102

ЖЦ = Последовательность сборки нашего приложения (Maven)
- generate-sources/generate-resources
- compile
- test-compile
- test
- package
- integration-test (pre & post)
- install 
- deploy


`40:01` : Плагины

- Все операции над проектом выполняются плагинами. Плагины выполняют императивные команды по сборке из наших хотелок в проект.
- Плагины в качестве точек входа содержат цели, связанные с ЖЦ:
    - Core: clean, deploy, compile, install, failsafe, resources, site, surefire
    - Packaging" jar, war, ear, rar ...
    - Reporting, Tools & 3rd-party
    

`41:30` : Дальнейшее развитие Ant+Ivy, Gradle

Ivy - менеджер ависимоти для Ant. 
Ivy тянет все зависимости из Maven2.

Добавление в build.xml:
```xml
<project xmlns:ivy="antlib:org.apache.ivy.ant ... >"
    <target name="resolve">
        <ivy:retrieve>
    </target>
```
Зависимости можно задать в файле ivy.xml:
```xml
<dependencies>
    <dependency org="javax.servlet"
                name="servlet-api"
                rev="2.5" />
</dependencies>
```

`43:43` : Чем не устраивает Ant и Maven? - XML

Чем хорош XML? 
- Легко проверяется корректность 
- можно осуществлять трансформацию во что-нибудь другое

`46:46` : Вторая проблема Ant и Maven - проприетарность.

Они оба предназначены для сборки Java-проектов, а Gradle:
- Нейтрален к языкам программирования
- Базируется на Ant+Ivy (в слайдах опечатка)
- Использует те же зависимости от Maven + может использовать его репозитории
- Использует ЖЦ и плагины как Maven
- DSL (Domain Specific Language) на Groovy в качестве скрипта сборки
- Плагины существуют для большого количества проектов
- Инкрементальная и параллельная сборки (есть почти везде)

Пример build.gradle
```groovy
apply plugin: "java"
apply plugin "application"

mainClassName = "ru.ifmo.cs.Bcomp-NG"

repositories {
    mavenCentral()
}
dependencies {
    compile "log4j:log4j-core:2.12.1
}
jar {
    manifest.attributes("Main-Class": mainClassName);
}
```

[Почитать про Gradle](https://habr.com/ru/post/225189/)

`50^40` : Платформо-зависимые системы сборки (вне Java)

- GNU autotools (C/C++), Cmake (C/C++), premake2 (lua)

Генерируются make-файлы на основании:
- Режимов работы программы
- Заданной конфигурации
- Операционной системы
- Фактического наличия библиотек

В чем отличие макроподстановки от компиляции программы с генерацией дерева?
Макроподстановка берет код и на заданных правилах меняет
одну последовательность символов на другую.

Пользователю нужно знать 3 команды: `./configure`, `make`, `sudo make install`

Тут неплохо бы было писать подробно процесс создания конфигурации проекта.
56 минут. я умираю


# [#6 Основы тестирования.](https://www.youtube.com/watch?v=_i2-oygZV7U&list=PLBWafxh1dFuykoWaAt7HiMOGgWXRvAN5V&index=6)

# [#7 Основы оптимизации производительности.](https://www.youtube.com/watch?v=fGsgQFhidzk&list=PLBWafxh1dFuykoWaAt7HiMOGgWXRvAN5V&index=7)

Кто занимается вопросами оптимизации?
- системный администратор:
    - с точки зрения операционной системы, деплоя приложения
    - смотрит сколько ресурсов занимают различные приложения внутри ОС
    - ОС имеет возможность регулировать выделяемые ресурсы
- опытный программист:
    - администратор занимается общим надсмотром за ПО и обычно просит программистов оптимизировать код, где он считает это нужно сделать
- **архитектор**:
    - смотрит на картину в целом
    - самая важная роль в оценке производительности
    
`1:20` : от чего зависит скорость выполнения программы:

стр. 148

- Как система построена, как блоки системы между собой связаны (системный и архитектурный аспект)
- Характеристики самой машины (низкоуровневый аппаратный аспект)
- То, как программисты пишут код, оптимальность выбранных алгоритмов
- Человеческий фактор

Программисты постоянно балансируют между скоростью выполнения и памятью

`7:46` - Влияние средств наблюдения на результаты. Как происходит анализ производительности. 

стр. 149

Анализ производительности - научный эксперимент.
- выбрать критерии оценки
- выбрать средства измерения
    - Неинтрузивные средства измерения = не влияют на результат
- выбрать нагрузку
    - стараться имитировать нагрузку, похожую на настоящую
    - это бывает сложная задача
- анализ результатов
- сделать небольшое изменение в системе, один участок кода
    - чтобы оттестировать именно то, что изменяли
- повторять до полного удовлетворения

`14:36` - Основные характеристики и ключевые понятия

стр. 150

- Время отклика,
    - ожидание от воздействия на систему до получения первых данных 
- Время полного обслуживания 
    - от начала запроса до полного его завершения
- Пропускная способность
    - сколько запросов в единицу времени можно сделать
- Утилизация и ожидание ресурса 
- точка насыщения и масштабируемость
- Эффективность
    - 100% загруженность CPU не означает, что наша программа работает эффективно
- Ускорение и прирост производительности
    - что произошло после тестирования и улучшения производительности системы
- Java: Скорость запуска memory foorprint
    - связано с Garbage collector
    - то, как программа себя ведет внутри памяти
    - сервера приложений могут запускаться очень долго
    
`17:55` - Поиск узких мест. Bottleneck

стр. 151

Классический "нисходящий" метод поиска узких мест:
- Исключение ошибок аппаратуры и администратора:
    - системные журналы, файлы конфигурации системы и прикладного ПО
- Общисистемный и межузловой мониторинг:
    - ОС сама собирает большое количество информации
    - Программисты обычно используют сторонние утилиты 
    - Если у вас кластер, для них есть отдельный набор своих утилит по мониторингу    
    - Анализируются: CPU, память, подсистема I/O, дисковые массивы, сеть, каналы передачи, ОС, виртуализация
- Мониторинг приложения: 
    - алгоритмы, проблемные API, многопоток, блокировки, синхронизации
    - сторонние прикладные API могут вредить производительности системы. Нужно четко понимать зачем нужна та или иная библиотека и какие накладные расходы она может дать. Можно она избыточная и проще будет написать какие-то модули руками
- Мониторинг микроархитектуры:
    - выравнивание данных — уверенность, что данные попадают в нужную строчку кэша
    - оптимизация кэшей
    - пузырьки конвейера
    - предсказание переходов

`30:25` - Пирамида памяти
    
стр. 152

![memory_pyromid.png](img/memory_pyromid.png)

- CPU : самая быстрая и самая дорогая память 
- L1 : очень быстрая память. Находится максимально близко к ядрам процессора
- L2, L3 : тоже находятся внутри процессора.
- RAM : бОльшее время доступа, но и внушительный объем.
- SSD : Существенно медленнее оперативной памяти. Условно в 1000 раз медленнее
- HDD : Еще примерно в 1000 раз медленнее

* - масштаб времени относительно процессора

`43:15` : Системный мониторинг производительности

стр. 153

- CPU : user%, system%, idle% (простой), прерывания, смена контекста (ctxt_sw), средняя нагрузка
- IO :  число байт читаемых и записываемых за секунду, и за какое количество операций это происходит; время ожидания
- VM :  (Виртуальная память) : скорость выделения, освобождения страниц, пейджинга, swap'инга
- Сеть : счетчики принятых/переданных данных, коллизий и тд

Системный мониторинг неинтрузивен (не оказывает влияния на производительность, так как счетчики автоматически включаются ОС.

`47:00` - Диспетчер процессов CPU

стр. 154

![cpu-dispatcher.png](img/cpu-dispatcher.png)

Вне зависимости от того, что происходит в системе, происходит прерывание часов на каждом из ядер процессора.
При этом на ядре могут выполняться как пользовательские, так и системные задачи.
Таски строятся в приоритетную очередь, соответственно одни могут вытесняться другими. 

Принцип разделения времени:
- Процессам которые стоят в очереди дольше, ОС обычно повышает приоритет, чтобы увеличить шансы их скорого выполнения.
- Процессам, которые свой квант времени использовали, ОС понижает приоритет

preemption - вытеснение процесса с процессора (involuntary context swith - несвободное переключение контекста) - в общем случае это не есть хорошо, тк переключение контекста затратная операция

57:10 - Виртуальная память

стр. 155

![img.png](img.png)

**Виртуальная память** — способ защиты системы. Внутри VM приложение думат, что работает в одних и тех же адресах. Потом просто эта память маппится в реальную.

Можно использовать странички повторно, использовать 
- **paging** : сброс неиспользуемых страниц на диск или их уничтожение, 
- **совместное использование библиотек** : VM позволяет сделать так, чтобы одна страничка памяти была подключена к разным процессам, вместо создания копии для каждого
- **swapping** : процесс целиком уходит в область подкачки





























